{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Qwen2.5-0.5B: Поиск оптимального слоя для QNLI\n","metadata":{}},{"cell_type":"markdown","source":"## Импорты и конфигурация","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom tqdm import tqdm\nimport gc\n\n# Конфигурация\nMODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\nMAX_LENGTH = 200\nBATCH_SIZE = 16\nPROBE_HIDDEN_DIM = 256\nLEARNING_RATE = 1e-3\nEPOCHS = 10\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Device: {DEVICE}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:22:52.162188Z","iopub.execute_input":"2025-12-01T17:22:52.162379Z","iopub.status.idle":"2025-12-01T17:22:57.280519Z","shell.execute_reply.started":"2025-12-01T17:22:52.162363Z","shell.execute_reply":"2025-12-01T17:22:57.279718Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Загрузка модели Qwen","metadata":{}},{"cell_type":"code","source":"# Загрузка модели\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    dtype=torch.float16,\n    device_map=\"auto\",\n    output_hidden_states=True\n)\nmodel.eval()\n\nNUM_LAYERS = model.config.num_hidden_layers\nprint(f\"Модель имеет {NUM_LAYERS} слоёв\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:22:58.780048Z","iopub.execute_input":"2025-12-01T17:22:58.780543Z","iopub.status.idle":"2025-12-01T17:23:25.218375Z","shell.execute_reply.started":"2025-12-01T17:22:58.780508Z","shell.execute_reply":"2025-12-01T17:23:25.217747Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 17:23:01.710740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764609781.905469     148 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764609781.965002     148 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2b315c5ae74754a0eafb5da047dea3"}},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b81e7d30505a43a891e5a17b56ade29e"}},"metadata":{}},{"name":"stdout","text":"Модель имеет 24 слоёв\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Загрузка датасета QNLI","metadata":{}},{"cell_type":"code","source":"# Загрузка данных\ndataset = load_dataset(\"glue\", \"qnli\")\ntrain_data = dataset[\"train\"].select(range(min(10000, len(dataset[\"train\"]))))\nval_data = dataset[\"validation\"]\n\nprint(f\"Train: {len(train_data)}, Val: {len(val_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:23:41.718148Z","iopub.execute_input":"2025-12-01T17:23:41.718783Z","iopub.status.idle":"2025-12-01T17:23:45.339304Z","shell.execute_reply.started":"2025-12-01T17:23:41.718761Z","shell.execute_reply":"2025-12-01T17:23:45.338684Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f435ed506b45d2965eda50970c1546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"qnli/train-00000-of-00001.parquet:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"138974cad63641eca45cfa0924c97b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"qnli/validation-00000-of-00001.parquet:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8951d25db3194095a705799920ec6701"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"qnli/test-00000-of-00001.parquet:   0%|          | 0.00/877k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c93ae71c77a545098b50faee6a7af89d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/104743 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01af4e5abce94f418b7c1aaa785377c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5463 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1c64cc42284494b6d27b992202fb99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5463 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee6dba414e1e4cab946625e566d48aa1"}},"metadata":{}},{"name":"stdout","text":"Train: 10000, Val: 5463\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Функции извлечения hidden states","metadata":{}},{"cell_type":"code","source":"def format_input(example):\n    return f\"Question: {example['question']}\\nSentence: {example['sentence']}\"\n\ndef extract_hidden_states(texts, layer):\n    \"\"\"Извлекаем hidden states из указанного слоя\"\"\"\n    all_hidden = []\n    \n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), BATCH_SIZE), desc=f\"Layer {layer}\"):\n            batch_texts = texts[i:i + BATCH_SIZE]\n            \n            inputs = tokenizer(\n                batch_texts,\n                return_tensors=\"pt\",\n                padding=True,\n                truncation=True,\n                max_length=MAX_LENGTH\n            ).to(DEVICE)\n            \n            outputs = model(**inputs, output_hidden_states=True)\n            hidden = outputs.hidden_states[layer]  # (batch, seq_len, hidden_dim)\n            \n            # Last token pooling\n            seq_lengths = inputs[\"attention_mask\"].sum(dim=1) - 1\n            pooled = hidden[torch.arange(hidden.size(0), device=DEVICE), seq_lengths]\n            \n            all_hidden.append(pooled.cpu().float())\n            \n            del outputs\n            torch.cuda.empty_cache()\n    \n    return torch.cat(all_hidden, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:23:45.340502Z","iopub.execute_input":"2025-12-01T17:23:45.340812Z","iopub.status.idle":"2025-12-01T17:23:45.347068Z","shell.execute_reply.started":"2025-12-01T17:23:45.340794Z","shell.execute_reply":"2025-12-01T17:23:45.346327Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## MLP Probe классификатор","metadata":{}},{"cell_type":"code","source":"class MLPProbe(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, num_classes=2):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim // 2, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:23:46.739981Z","iopub.execute_input":"2025-12-01T17:23:46.740554Z","iopub.status.idle":"2025-12-01T17:23:46.745084Z","shell.execute_reply.started":"2025-12-01T17:23:46.740532Z","shell.execute_reply":"2025-12-01T17:23:46.744329Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Функция обучения","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate(train_features, train_labels, val_features, val_labels, epochs=EPOCHS):\n    \"\"\"Обучаем probe и возвращаем лучшую accuracy\"\"\"\n    hidden_dim = train_features.shape[1]\n    \n    train_loader = DataLoader(\n        TensorDataset(train_features, train_labels), \n        batch_size=64, shuffle=True\n    )\n    val_loader = DataLoader(\n        TensorDataset(val_features, val_labels), \n        batch_size=64\n    )\n    \n    probe = MLPProbe(hidden_dim, PROBE_HIDDEN_DIM).to(DEVICE)\n    optimizer = torch.optim.AdamW(probe.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n    \n    best_val_acc = 0\n    best_probe_state = None\n    \n    for epoch in range(epochs):\n        # Train\n        probe.train()\n        for features, labels in train_loader:\n            features, labels = features.to(DEVICE), labels.to(DEVICE)\n            loss = criterion(probe(features), labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        \n        # Eval\n        probe.eval()\n        all_preds = []\n        with torch.no_grad():\n            for features, labels in val_loader:\n                preds = probe(features.to(DEVICE)).argmax(dim=-1).cpu()\n                all_preds.extend(preds.tolist())\n        \n        val_acc = accuracy_score(val_labels.tolist(), all_preds)\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_probe_state = probe.state_dict().copy()\n        \n        print(f\"  Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n    \n    # Возвращаем лучшую модель\n    probe.load_state_dict(best_probe_state)\n    return probe, best_val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:23:50.283218Z","iopub.execute_input":"2025-12-01T17:23:50.283955Z","iopub.status.idle":"2025-12-01T17:23:50.291064Z","shell.execute_reply.started":"2025-12-01T17:23:50.283926Z","shell.execute_reply":"2025-12-01T17:23:50.290314Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Подготовка данных","metadata":{}},{"cell_type":"code","source":"# Подготовка текстов и меток\ntrain_texts = [format_input(ex) for ex in train_data]\nval_texts = [format_input(ex) for ex in val_data]\ntrain_labels = torch.tensor([ex[\"label\"] for ex in train_data])\nval_labels = torch.tensor([ex[\"label\"] for ex in val_data])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:23:53.202560Z","iopub.execute_input":"2025-12-01T17:23:53.202883Z","iopub.status.idle":"2025-12-01T17:23:54.386991Z","shell.execute_reply.started":"2025-12-01T17:23:53.202830Z","shell.execute_reply":"2025-12-01T17:23:54.386183Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Поиск лучшего слоя","metadata":{}},{"cell_type":"code","source":"# Поиск лучшего слоя\nlayers_to_test = [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\nprint(f\"Тестируем слои: {layers_to_test}\")\n\nresults = {}\n\nfor layer in layers_to_test:\n    print(f\"\\n{'='*40}\")\n    print(f\"Слой {layer}\")\n    print('='*40)\n    \n    train_features = extract_hidden_states(train_texts, layer)\n    val_features = extract_hidden_states(val_texts, layer)\n    \n    _, best_acc = train_and_evaluate(train_features, train_labels, val_features, val_labels)\n    results[layer] = best_acc\n    \n    del train_features, val_features\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# Результаты поиска\nprint(\"\\n\" + \"=\"*40)\nprint(\"РЕЗУЛЬТАТЫ ПОИСКА ЛУЧШЕГО СЛОЯ\")\nprint(\"=\"*40)\nfor layer, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n    print(f\"Layer {layer:2d}: {acc:.4f}\")\n\nbest_layer = max(results, key=results.get)\nprint(f\"\\nЛучший слой: {best_layer} (accuracy: {results[best_layer]:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:23:56.123935Z","iopub.execute_input":"2025-12-01T17:23:56.124637Z","iopub.status.idle":"2025-12-01T17:43:44.677658Z","shell.execute_reply.started":"2025-12-01T17:23:56.124612Z","shell.execute_reply":"2025-12-01T17:43:44.677075Z"}},"outputs":[{"name":"stdout","text":"Тестируем слои: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n\n========================================\nСлой 12\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 12: 100%|██████████| 625/625 [01:04<00:00,  9.66it/s]\nLayer 12: 100%|██████████| 342/342 [00:37<00:00,  9.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.7721\n  Epoch 2: Val Acc = 0.7668\n  Epoch 3: Val Acc = 0.7778\n  Epoch 4: Val Acc = 0.7939\n  Epoch 5: Val Acc = 0.7651\n  Epoch 6: Val Acc = 0.7785\n  Epoch 7: Val Acc = 0.7924\n  Epoch 8: Val Acc = 0.7974\n  Epoch 9: Val Acc = 0.7963\n  Epoch 10: Val Acc = 0.7915\n\n========================================\nСлой 13\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 13: 100%|██████████| 625/625 [01:06<00:00,  9.38it/s]\nLayer 13: 100%|██████████| 342/342 [00:37<00:00,  9.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8345\n  Epoch 2: Val Acc = 0.8504\n  Epoch 3: Val Acc = 0.8481\n  Epoch 4: Val Acc = 0.8530\n  Epoch 5: Val Acc = 0.8526\n  Epoch 6: Val Acc = 0.8514\n  Epoch 7: Val Acc = 0.8433\n  Epoch 8: Val Acc = 0.8466\n  Epoch 9: Val Acc = 0.8470\n  Epoch 10: Val Acc = 0.8418\n\n========================================\nСлой 14\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 14: 100%|██████████| 625/625 [01:07<00:00,  9.32it/s]\nLayer 14: 100%|██████████| 342/342 [00:37<00:00,  9.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8429\n  Epoch 2: Val Acc = 0.8504\n  Epoch 3: Val Acc = 0.8499\n  Epoch 4: Val Acc = 0.8360\n  Epoch 5: Val Acc = 0.8479\n  Epoch 6: Val Acc = 0.8532\n  Epoch 7: Val Acc = 0.8364\n  Epoch 8: Val Acc = 0.8499\n  Epoch 9: Val Acc = 0.8492\n  Epoch 10: Val Acc = 0.8477\n\n========================================\nСлой 15\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 15: 100%|██████████| 625/625 [01:06<00:00,  9.44it/s]\nLayer 15: 100%|██████████| 342/342 [00:37<00:00,  9.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8428\n  Epoch 2: Val Acc = 0.8182\n  Epoch 3: Val Acc = 0.8407\n  Epoch 4: Val Acc = 0.7701\n  Epoch 5: Val Acc = 0.8486\n  Epoch 6: Val Acc = 0.8468\n  Epoch 7: Val Acc = 0.8490\n  Epoch 8: Val Acc = 0.8309\n  Epoch 9: Val Acc = 0.8431\n  Epoch 10: Val Acc = 0.8444\n\n========================================\nСлой 16\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 16: 100%|██████████| 625/625 [01:05<00:00,  9.48it/s]\nLayer 16: 100%|██████████| 342/342 [00:37<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8389\n  Epoch 2: Val Acc = 0.8386\n  Epoch 3: Val Acc = 0.8270\n  Epoch 4: Val Acc = 0.8418\n  Epoch 5: Val Acc = 0.8472\n  Epoch 6: Val Acc = 0.8464\n  Epoch 7: Val Acc = 0.8420\n  Epoch 8: Val Acc = 0.8486\n  Epoch 9: Val Acc = 0.8415\n  Epoch 10: Val Acc = 0.8437\n\n========================================\nСлой 17\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 17: 100%|██████████| 625/625 [01:06<00:00,  9.41it/s]\nLayer 17: 100%|██████████| 342/342 [00:37<00:00,  9.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8287\n  Epoch 2: Val Acc = 0.8373\n  Epoch 3: Val Acc = 0.8411\n  Epoch 4: Val Acc = 0.8409\n  Epoch 5: Val Acc = 0.8380\n  Epoch 6: Val Acc = 0.8451\n  Epoch 7: Val Acc = 0.8455\n  Epoch 8: Val Acc = 0.8402\n  Epoch 9: Val Acc = 0.8338\n  Epoch 10: Val Acc = 0.8389\n\n========================================\nСлой 18\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 18: 100%|██████████| 625/625 [01:06<00:00,  9.45it/s]\nLayer 18: 100%|██████████| 342/342 [00:37<00:00,  9.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8257\n  Epoch 2: Val Acc = 0.8133\n  Epoch 3: Val Acc = 0.8288\n  Epoch 4: Val Acc = 0.7889\n  Epoch 5: Val Acc = 0.8351\n  Epoch 6: Val Acc = 0.8312\n  Epoch 7: Val Acc = 0.8373\n  Epoch 8: Val Acc = 0.8144\n  Epoch 9: Val Acc = 0.8428\n  Epoch 10: Val Acc = 0.8431\n\n========================================\nСлой 19\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 19: 100%|██████████| 625/625 [01:06<00:00,  9.47it/s]\nLayer 19: 100%|██████████| 342/342 [00:37<00:00,  9.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8124\n  Epoch 2: Val Acc = 0.8331\n  Epoch 3: Val Acc = 0.8301\n  Epoch 4: Val Acc = 0.8195\n  Epoch 5: Val Acc = 0.8256\n  Epoch 6: Val Acc = 0.8332\n  Epoch 7: Val Acc = 0.8351\n  Epoch 8: Val Acc = 0.8307\n  Epoch 9: Val Acc = 0.8402\n  Epoch 10: Val Acc = 0.8083\n\n========================================\nСлой 20\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 20: 100%|██████████| 625/625 [01:05<00:00,  9.49it/s]\nLayer 20: 100%|██████████| 342/342 [00:37<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8120\n  Epoch 2: Val Acc = 0.8221\n  Epoch 3: Val Acc = 0.8080\n  Epoch 4: Val Acc = 0.8305\n  Epoch 5: Val Acc = 0.7600\n  Epoch 6: Val Acc = 0.8338\n  Epoch 7: Val Acc = 0.8186\n  Epoch 8: Val Acc = 0.8102\n  Epoch 9: Val Acc = 0.8294\n  Epoch 10: Val Acc = 0.8307\n\n========================================\nСлой 21\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 21: 100%|██████████| 625/625 [01:05<00:00,  9.48it/s]\nLayer 21: 100%|██████████| 342/342 [00:37<00:00,  9.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.6738\n  Epoch 2: Val Acc = 0.8078\n  Epoch 3: Val Acc = 0.8107\n  Epoch 4: Val Acc = 0.8083\n  Epoch 5: Val Acc = 0.8113\n  Epoch 6: Val Acc = 0.8188\n  Epoch 7: Val Acc = 0.7937\n  Epoch 8: Val Acc = 0.8041\n  Epoch 9: Val Acc = 0.8105\n  Epoch 10: Val Acc = 0.8036\n\n========================================\nСлой 22\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 22: 100%|██████████| 625/625 [01:05<00:00,  9.49it/s]\nLayer 22: 100%|██████████| 342/342 [00:37<00:00,  9.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.7706\n  Epoch 2: Val Acc = 0.7895\n  Epoch 3: Val Acc = 0.8029\n  Epoch 4: Val Acc = 0.8054\n  Epoch 5: Val Acc = 0.7961\n  Epoch 6: Val Acc = 0.8045\n  Epoch 7: Val Acc = 0.8030\n  Epoch 8: Val Acc = 0.7844\n  Epoch 9: Val Acc = 0.8065\n  Epoch 10: Val Acc = 0.7968\n\n========================================\nРЕЗУЛЬТАТЫ ПОИСКА ЛУЧШЕГО СЛОЯ\n========================================\nLayer 14: 0.8532\nLayer 13: 0.8530\nLayer 15: 0.8490\nLayer 16: 0.8486\nLayer 17: 0.8455\nLayer 18: 0.8431\nLayer 19: 0.8402\nLayer 20: 0.8338\nLayer 21: 0.8188\nLayer 22: 0.8065\nLayer 12: 0.7974\n\nЛучший слой: 14 (accuracy: 0.8532)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Финальная модель на лучшем слое","metadata":{}},{"cell_type":"code","source":"# Финальное обучение на лучшем слое\nprint(f\"\\n{'='*40}\")\nprint(f\"ФИНАЛЬНАЯ МОДЕЛЬ НА СЛОЕ {best_layer}\")\nprint('='*40)\n\ntrain_features = extract_hidden_states(train_texts, best_layer)\nval_features = extract_hidden_states(val_texts, best_layer)\n\nbest_probe, _ = train_and_evaluate(train_features, train_labels, val_features, val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:43:44.678776Z","iopub.execute_input":"2025-12-01T17:43:44.679083Z","iopub.status.idle":"2025-12-01T17:45:32.096406Z","shell.execute_reply.started":"2025-12-01T17:43:44.679064Z","shell.execute_reply":"2025-12-01T17:45:32.095746Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nФИНАЛЬНАЯ МОДЕЛЬ НА СЛОЕ 14\n========================================\n","output_type":"stream"},{"name":"stderr","text":"Layer 14: 100%|██████████| 625/625 [01:05<00:00,  9.48it/s]\nLayer 14: 100%|██████████| 342/342 [00:37<00:00,  9.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 1: Val Acc = 0.8060\n  Epoch 2: Val Acc = 0.8492\n  Epoch 3: Val Acc = 0.8528\n  Epoch 4: Val Acc = 0.8539\n  Epoch 5: Val Acc = 0.8517\n  Epoch 6: Val Acc = 0.8455\n  Epoch 7: Val Acc = 0.8514\n  Epoch 8: Val Acc = 0.8466\n  Epoch 9: Val Acc = 0.8494\n  Epoch 10: Val Acc = 0.8393\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Метрики на обучающей выборке","metadata":{}},{"cell_type":"code","source":"# Метрики на TRAIN\nbest_probe.eval()\ntrain_loader = DataLoader(TensorDataset(train_features, train_labels), batch_size=64)\n\ntrain_preds = []\nwith torch.no_grad():\n    for features, _ in train_loader:\n        preds = best_probe(features.to(DEVICE)).argmax(dim=-1).cpu()\n        train_preds.extend(preds.tolist())\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"МЕТРИКИ НА TRAIN\")\nprint(\"=\"*50)\nprint(f\"Accuracy: {accuracy_score(train_labels.tolist(), train_preds):.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(train_labels.tolist(), train_preds, target_names=[\"entailment\", \"not_entailment\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:45:32.097151Z","iopub.execute_input":"2025-12-01T17:45:32.097429Z","iopub.status.idle":"2025-12-01T17:45:32.258149Z","shell.execute_reply.started":"2025-12-01T17:45:32.097406Z","shell.execute_reply":"2025-12-01T17:45:32.257490Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nМЕТРИКИ НА TRAIN\n==================================================\nAccuracy: 0.8514\n\nClassification Report:\n                precision    recall  f1-score   support\n\n    entailment       0.92      0.77      0.84      5034\nnot_entailment       0.80      0.93      0.86      4966\n\n      accuracy                           0.85     10000\n     macro avg       0.86      0.85      0.85     10000\n  weighted avg       0.86      0.85      0.85     10000\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Метрики на валидационной выборке","metadata":{}},{"cell_type":"code","source":"# Метрики на VALIDATION\nval_loader = DataLoader(TensorDataset(val_features, val_labels), batch_size=64)\n\nval_preds = []\nwith torch.no_grad():\n    for features, _ in val_loader:\n        preds = best_probe(features.to(DEVICE)).argmax(dim=-1).cpu()\n        val_preds.extend(preds.tolist())\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"МЕТРИКИ НА VALIDATION\")\nprint(\"=\"*50)\nprint(f\"Accuracy: {accuracy_score(val_labels.tolist(), val_preds):.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(val_labels.tolist(), val_preds, target_names=[\"entailment\", \"not_entailment\"]))\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(val_labels.tolist(), val_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:45:32.259303Z","iopub.execute_input":"2025-12-01T17:45:32.259508Z","iopub.status.idle":"2025-12-01T17:45:32.359439Z","shell.execute_reply.started":"2025-12-01T17:45:32.259494Z","shell.execute_reply":"2025-12-01T17:45:32.358906Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nМЕТРИКИ НА VALIDATION\n==================================================\nAccuracy: 0.8393\n\nClassification Report:\n                precision    recall  f1-score   support\n\n    entailment       0.89      0.77      0.83      2702\nnot_entailment       0.80      0.90      0.85      2761\n\n      accuracy                           0.84      5463\n     macro avg       0.84      0.84      0.84      5463\n  weighted avg       0.84      0.84      0.84      5463\n\n\nConfusion Matrix:\n[[2092  610]\n [ 268 2493]]\n","output_type":"stream"}],"execution_count":11}]}