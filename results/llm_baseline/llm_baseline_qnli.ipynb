{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM Zero-Shot Evaluation on QNLI\n\nОценка базовой языковой модели **Qwen2.5-0.5B** на задаче QNLI без дообучения.","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n\nMODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\nBATCH_SIZE = 8\nMAX_LENGTH = 512\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Device: {DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:24:20.959076Z","iopub.execute_input":"2025-12-01T15:24:20.959481Z","iopub.status.idle":"2025-12-01T15:24:20.963736Z","shell.execute_reply.started":"2025-12-01T15:24:20.959463Z","shell.execute_reply":"2025-12-01T15:24:20.963079Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## 2. Load Dataset\n\nQNLI (Question-answering Natural Language Inference) - задача определения, содержит ли предложение ответ на вопрос.","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"glue\", \"qnli\", split=\"validation\")\nprint(f\"Validation size: {len(dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:24:20.964435Z","iopub.execute_input":"2025-12-01T15:24:20.964687Z","iopub.status.idle":"2025-12-01T15:24:21.670085Z","shell.execute_reply.started":"2025-12-01T15:24:20.964665Z","shell.execute_reply":"2025-12-01T15:24:21.669493Z"}},"outputs":[{"name":"stdout","text":"Validation size: 5463\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## 3. Load Model\n\nИспользуем decoder-only модель с left-padding для корректной генерации.","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.padding_side = \"left\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n).to(DEVICE)\nmodel.eval()\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:24:21.671456Z","iopub.execute_input":"2025-12-01T15:24:21.671974Z","iopub.status.idle":"2025-12-01T15:24:23.442273Z","shell.execute_reply.started":"2025-12-01T15:24:21.671954Z","shell.execute_reply":"2025-12-01T15:24:23.441489Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## 4. Prompt Engineering\n\nПростой промпт с явным указанием формата ответа.","metadata":{}},{"cell_type":"code","source":"def create_prompt(question, sentence):\n    return f\"\"\"Does the sentence answer the question?\n\nQuestion: {question}\nSentence: {sentence}\n\nAnswer with only \"yes\" or \"no\":\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:24:23.443112Z","iopub.execute_input":"2025-12-01T15:24:23.443368Z","iopub.status.idle":"2025-12-01T15:24:23.447166Z","shell.execute_reply.started":"2025-12-01T15:24:23.443350Z","shell.execute_reply":"2025-12-01T15:24:23.446525Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def parse_answer(text):\n    \"\"\"Парсим ответ модели\"\"\"\n    text = text.lower().strip()\n    if \"yes\" in text:\n        return 0  # entailment\n    elif \"no\" in text:\n        return 1  # not_entailment\n    else:\n        return -1  # не распознано","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:24:23.447821Z","iopub.execute_input":"2025-12-01T15:24:23.448025Z","iopub.status.idle":"2025-12-01T15:24:23.467600Z","shell.execute_reply.started":"2025-12-01T15:24:23.448011Z","shell.execute_reply":"2025-12-01T15:24:23.466991Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## 5. Inference\n\nГенерация ответов для всего validation set.","metadata":{}},{"cell_type":"code","source":"all_preds = []\nall_labels = []\nraw_outputs = []\n\nwith torch.no_grad():\n    for i in tqdm(range(0, len(dataset), BATCH_SIZE), desc=\"Evaluating\"):\n        batch = dataset[i:i+BATCH_SIZE]\n        \n        prompts = [\n            create_prompt(q, s) \n            for q, s in zip(batch[\"question\"], batch[\"sentence\"])\n        ]\n        \n        inputs = tokenizer(\n            prompts,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=MAX_LENGTH\n        ).to(DEVICE)\n        \n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=5,\n            do_sample=False,\n            pad_token_id=tokenizer.pad_token_id\n        )\n        \n        for j, output in enumerate(outputs):\n            input_len = inputs[\"input_ids\"][j].shape[0]\n            generated = tokenizer.decode(output[input_len:], skip_special_tokens=True)\n            raw_outputs.append(generated)\n            all_preds.append(parse_answer(generated))\n        \n        all_labels.extend(batch[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:24:38.367518Z","iopub.execute_input":"2025-12-01T15:24:38.367798Z","iopub.status.idle":"2025-12-01T15:25:35.389851Z","shell.execute_reply.started":"2025-12-01T15:24:38.367775Z","shell.execute_reply":"2025-12-01T15:25:35.389109Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 683/683 [00:57<00:00, 11.98it/s]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 6. Analysis of Generated Answers\n\nПроверяем, что генерирует модель.","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\nprint(\"Распределение ответов модели:\")\nprint(Counter(raw_outputs).most_common(10))\n\nunrecognized = sum(1 for p in all_preds if p == -1)\nprint(f\"\\nНе распознано: {unrecognized} ({unrecognized/len(all_preds)*100:.1f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:25:35.391671Z","iopub.execute_input":"2025-12-01T15:25:35.391963Z","iopub.status.idle":"2025-12-01T15:25:35.397934Z","shell.execute_reply.started":"2025-12-01T15:25:35.391945Z","shell.execute_reply":"2025-12-01T15:25:35.397215Z"}},"outputs":[{"name":"stdout","text":"Распределение ответов модели:\n[(' no', 3292), (' yes', 2170), (' yes\\nYou are an', 1)]\n\nНе распознано: 0 (0.0%)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## 7. Results\n\nМетрики производительности модели.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nvalid_idx = [i for i, p in enumerate(all_preds) if p != -1]\nfiltered_preds = [all_preds[i] for i in valid_idx]\nfiltered_labels = [all_labels[i] for i in valid_idx]\n\nprint(f\"Оценка на {len(filtered_preds)} из {len(all_preds)} примеров\")\n\naccuracy = accuracy_score(filtered_labels, filtered_preds)\nprint(f\"\\n{'='*50}\")\nprint(f\"ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\nprint(f\"{'='*50}\")\n\nprint(f\"\\nClassification Report:\")\nprint(classification_report(filtered_labels, filtered_preds, target_names=[\"entailment\", \"not_entailment\"]))\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(filtered_labels, filtered_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:25:35.398500Z","iopub.execute_input":"2025-12-01T15:25:35.398715Z","iopub.status.idle":"2025-12-01T15:25:35.437357Z","shell.execute_reply.started":"2025-12-01T15:25:35.398695Z","shell.execute_reply":"2025-12-01T15:25:35.436569Z"}},"outputs":[{"name":"stdout","text":"Оценка на 5463 из 5463 примеров\n\n==================================================\nACCURACY: 0.5792 (57.92%)\n==================================================\n\nClassification Report:\n                precision    recall  f1-score   support\n\n    entailment       0.59      0.48      0.53      2702\nnot_entailment       0.57      0.68      0.62      2761\n\n      accuracy                           0.58      5463\n     macro avg       0.58      0.58      0.57      5463\n  weighted avg       0.58      0.58      0.57      5463\n\nConfusion Matrix:\n[[1287 1415]\n [ 884 1877]]\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## 8. Examples\n\nПримеры предсказаний модели.","metadata":{}},{"cell_type":"code","source":"print(\"\\nПРИМЕРЫ:\")\nfor i in range(10):\n    true_label = \"entailment\" if all_labels[i] == 0 else \"not_entailment\"\n    pred_label = \"entailment\" if all_preds[i] == 0 else (\"not_entailment\" if all_preds[i] == 1 else \"???\")\n    mark = \"✓\" if all_labels[i] == all_preds[i] else \"✗\"\n    print(f\"{mark} '{raw_outputs[i][:15]:<15}' | Pred: {pred_label:<15} | True: {true_label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T15:25:35.438452Z","iopub.execute_input":"2025-12-01T15:25:35.438645Z","iopub.status.idle":"2025-12-01T15:25:35.443468Z","shell.execute_reply.started":"2025-12-01T15:25:35.438630Z","shell.execute_reply":"2025-12-01T15:25:35.442804Z"}},"outputs":[{"name":"stdout","text":"\nПРИМЕРЫ:\n✓ ' yes           ' | Pred: entailment      | True: entailment\n✓ ' no            ' | Pred: not_entailment  | True: not_entailment\n✗ ' yes           ' | Pred: entailment      | True: not_entailment\n✗ ' no            ' | Pred: not_entailment  | True: entailment\n✗ ' yes           ' | Pred: entailment      | True: not_entailment\n✗ ' yes           ' | Pred: entailment      | True: not_entailment\n✓ ' no            ' | Pred: not_entailment  | True: not_entailment\n✓ ' no            ' | Pred: not_entailment  | True: not_entailment\n✗ ' yes           ' | Pred: entailment      | True: not_entailment\n✗ ' no            ' | Pred: not_entailment  | True: entailment\n","output_type":"stream"}],"execution_count":33}]}